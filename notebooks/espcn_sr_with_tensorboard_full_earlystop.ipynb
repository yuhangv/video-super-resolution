{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ESPCN SR with TensorBoard & Network Visualization\n\nThis notebook trains a stronger ESPCN model, logs scalars and images to TensorBoard, and shows model summaries and a computation graph.\n\n**Features:**\n- stronger ESPCN (64->32 filters)\n- Charbonnier loss\n- data augmentation\n- checkpointing\n- TensorBoard logging: loss, PSNR, SSIM, and example images\n- network summary (torchsummary) and computation graph (torchviz)\n\nRun on Colab with GPU runtime for best results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install required packages\n!pip install torch torchvision tensorboard pillow scikit-image torchsummary torchviz --quiet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Imports\nimport os, zipfile, requests, io, random\nfrom pathlib import Path\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\n\nfrom torch.utils.tensorboard import SummaryWriter\nfrom skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n\n# visualization helpers\nfrom torchsummary import summary\nfrom torchviz import make_dot\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download DIV2K (small subset)\nWe download the training HR zip and extract. This may take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Download a smaller subset or the full train set depending on availability\nurl = 'http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip'\nif not os.path.exists('DIV2K_train_HR'):\n    print('Downloading DIV2K_train_HR.zip (this may be large)...')\n    r = requests.get(url, stream=True)\n    open('DIV2K_train_HR.zip','wb').write(r.content)\n    with zipfile.ZipFile('DIV2K_train_HR.zip','r') as z:\n        z.extractall('DIV2K_train_HR')\n    # many files extracted into DIV2K_train_HR/DIV2K_train_HR\n    # normalize path\n    if os.path.exists('DIV2K_train_HR/DIV2K_train_HR'):\n        os.rename('DIV2K_train_HR/DIV2K_train_HR', 'DIV2K_train_HR/images')\n    else:\n        # move pngs into folder images\n        os.makedirs('DIV2K_train_HR/images', exist_ok=True)\n        for f in os.listdir('DIV2K_train_HR'):\n            if f.endswith('.png'):\n                os.rename(os.path.join('DIV2K_train_HR', f), os.path.join('DIV2K_train_HR/images', f))\n\n# collect image folder\nif os.path.exists('DIV2K_train_HR/images'):\n    data_root = 'DIV2K_train_HR/images'\nelse:\n    data_root = 'DIV2K_train_HR'\n\nprint('Data root:', data_root)\nprint('Found', len([f for f in os.listdir(data_root) if f.lower().endswith('.png')]), 'images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset and augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class SRDataset(Dataset):\n    def __init__(self, root, scale=2, patch_size=96, train=True, max_images=None):\n        self.files = sorted([os.path.join(root, x) for x in os.listdir(root) if x.lower().endswith('.png')])\n        if max_images:\n            self.files = self.files[:max_images]\n        self.scale = scale\n        self.patch_size = patch_size\n        self.train = train\n        self.to_tensor = transforms.ToTensor()\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.files[idx]).convert('RGB')\n        if self.train:\n            w,h = img.size\n            if w < self.patch_size or h < self.patch_size:\n                img = img.resize((self.patch_size, self.patch_size), Image.BICUBIC)\n                w,h = img.size\n            x = random.randint(0, w-self.patch_size)\n            y = random.randint(0, h-self.patch_size)\n            hr = img.crop((x,y,x+self.patch_size,y+self.patch_size))\n            # augment\n            if random.random() < 0.5:\n                hr = hr.transpose(Image.FLIP_LEFT_RIGHT)\n            if random.random() < 0.5:\n                hr = hr.transpose(Image.FLIP_TOP_BOTTOM)\n            if random.random() < 0.5:\n                hr = hr.rotate(90)\n        else:\n            hr = img.resize((self.patch_size, self.patch_size), Image.BICUBIC)\n        lr = hr.resize((hr.size[0]//self.scale, hr.size[1]//self.scale), Image.BICUBIC)\n        lr_up = lr.resize(hr.size, Image.BICUBIC)\n        return self.to_tensor(lr), self.to_tensor(hr), self.to_tensor(lr_up)\n\n# small subset for quick runs\ntrain_ds = SRDataset(data_root, train=True, max_images=None)\nval_ds = SRDataset(data_root, train=False, max_images=None)\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=1, shuffle=True, num_workers=1)\nprint('Train size:', len(train_ds), 'Val size:', len(val_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model: stronger ESPCN + Charbonnier loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class ESPCN(nn.Module):\n    def __init__(self, scale=2):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=2)\n        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(32, scale*scale*3, kernel_size=3, padding=1)\n        self.pixel_shuffle = nn.PixelShuffle(scale)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.pixel_shuffle(self.conv3(x))\n        return x\n\nclass CharbonnierLoss(nn.Module):\n    def __init__(self, eps=1e-6):\n        super().__init__()\n        self.eps = eps\n    def forward(self, pred, target):\n        return torch.mean(torch.sqrt((pred - target) ** 2 + self.eps))\n\nmodel = ESPCN(scale=2).to(device)\nprint('Model created on', device)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Network text summary\ntry:\n    summary(model, (3, 48, 48))\nexcept Exception as e:\n    print('torchsummary failed:', e)\n\n# Computation graph via torchviz (make_dot)\ntry:\n    dummy = torch.randn(1,3,48,48).to(device)\n    out = model(dummy)\n    g = make_dot(out, params=dict(list(model.named_parameters())))\n    g.format = 'png'\n    g.render('espcn_graph', cleanup=True)\n    from IPython.display import Image, display\n    display(Image('espcn_graph.png'))\nexcept Exception as e:\n    print('torchviz graph failed:', e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training loop with TensorBoard logging and checkpoints\nWe will log: training loss per step, and per-epoch validation PSNR/SSIM. We also log image triplets (LR upsample, SR, HR) to TensorBoard every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "writer = SummaryWriter(log_dir='runs/espcn_experiment')\ncriterion = CharbonnierLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\nstart_epoch = 0\nckpt_path = 'espcn_tb_checkpoint.pth'\nif os.path.exists(ckpt_path):\n    ckpt = torch.load(ckpt_path, map_location=device)\n    model.load_state_dict(ckpt['model'])\n    optimizer.load_state_dict(ckpt['optim'])\n    start_epoch = ckpt['epoch']\n    print('Resumed from', start_epoch)\n\nnum_epochs = 200\nglobal_step = 0\nfor epoch in range(start_epoch, num_epochs):\n    model.train()\n    running_loss = 0.0\n    for i, (lr, hr, lr_up) in enumerate(train_loader):\n        lr = lr.to(device)\n        hr = hr.to(device)\n        sr = model(lr)\n        loss = criterion(sr, hr)\n        optimizer.zero_grad(); loss.backward(); optimizer.step()\n        running_loss += loss.item()\n        writer.add_scalar('train/loss', loss.item(), global_step)\n        global_step += 1\n    avg_loss = running_loss / len(train_loader)\n    print(f'Epoch {epoch+1}/{num_epochs} - train loss {avg_loss:.6f}')\n\n    # Validation: compute PSNR/SSIM average on val set (first N)\n    model.eval()\n    psnr_b, psnr_sr, ssim_b, ssim_sr = [], [], [], []\n    with torch.no_grad():\n        for j, (lr, hr, lr_up) in enumerate(val_loader):\n            if j >= 10: break\n            lr = lr.to(device); hr = hr.to(device); lr_up = lr_up.to(device)\n            sr = model(lr)\n            hr_np = hr.squeeze().permute(1,2,0).cpu().numpy()\n            bic_np = lr_up.squeeze().permute(1,2,0).cpu().numpy()\n            sr_np = sr.squeeze().permute(1,2,0).cpu().numpy()\n            psnr_b.append(psnr(hr_np, bic_np, data_range=1.0))\n            psnr_sr.append(psnr(hr_np, sr_np, data_range=1.0))\n            ssim_b.append(ssim(hr_np, bic_np, channel_axis=2, data_range=1.0))\n            ssim_sr.append(ssim(hr_np, sr_np, channel_axis=2, data_range=1.0))\n            # log images for the first val sample only\n            if j==0:\n                # make a grid: LR up, SR, HR\n                grid = utils.make_grid([lr_up.squeeze().cpu(), sr.squeeze().cpu().clamp(0,1), hr.squeeze().cpu()], nrow=3)\n                writer.add_image('val/sample_epoch_%d' % (epoch+1), grid, epoch)\n    mean_psnr_b = np.mean(psnr_b); mean_psnr_sr = np.mean(psnr_sr)\n    mean_ssim_b = np.mean(ssim_b); mean_ssim_sr = np.mean(ssim_sr)\n    print(f'Val PSNR Bicubic: {mean_psnr_b:.3f}, SR: {mean_psnr_sr:.3f} | SSIM Bicubic: {mean_ssim_b:.4f}, SR: {mean_ssim_sr:.4f}')\n\n    writer.add_scalar('val/psnr_bic', mean_psnr_b, epoch)\n    writer.add_scalar('val/psnr_sr', mean_psnr_sr, epoch)\n    writer.add_scalar('val/ssim_bic', mean_ssim_b, epoch)\n    writer.add_scalar('val/ssim_sr', mean_ssim_sr, epoch)\n\n    # checkpoint\n    torch.save({'epoch': epoch+1, 'model': model.state_dict(), 'optim': optimizer.state_dict()}, ckpt_path)\n\nwriter.close()\nprint('Training finished. Run `tensorboard --logdir runs/espcn_experiment` to inspect.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to run TensorBoard in Colab\nIn Colab run:\n\n```python\n%load_ext tensorboard\n%tensorboard --logdir runs/espcn_experiment\n```\n\nThis will open an inline TensorBoard where you can view scalars and images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n- For better final performance, set `num_epochs=200+` and use more training images (remove `max_images` limits). \n- If `torchviz` fails due to Graphviz not installed, you can install system packages in Colab (`apt-get install graphviz`) or rely on the textual `torchsummary` output.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}